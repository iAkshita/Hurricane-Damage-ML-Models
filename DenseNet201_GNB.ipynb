{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":742001,"sourceType":"datasetVersion","datasetId":383256}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing essential libraries\nimport os  # Operating system related functions\nimport numpy as nu  # Numerical computing library\nimport pandas as ps  # Data manipulation library\nimport seaborn as sb  # Data visualization library\nimport tensorflow as tnf  # Deep learning framework\nfrom tensorflow.keras.applications.densenet import DenseNet201  # Pre-trained model\nfrom tensorflow.keras.preprocessing import image  # Image preprocessing\nfrom tensorflow.keras.applications.densenet import preprocess_input  # Preprocessing function for DenseNet\nfrom tensorflow.keras.layers import Dense, Dropout  # Neural network layers\nimport itertools  # Utility functions for iterating\nfrom tensorflow.keras.models import Sequential  # Sequential neural network model\nfrom tensorflow.keras.regularizers import l2  # L2 regularization\nfrom keras.utils.vis_utils import plot_model  # Model visualization\nfrom sklearn.model_selection import train_test_split  # Splitting dataset\nfrom sklearn.metrics import classification_report  # Classification report\nfrom sklearn.metrics import confusion_matrix  # Confusion matrix\nfrom sklearn.metrics import matthews_corrcoef as MTC  # Matthews correlation coefficient\nfrom sklearn.metrics import balanced_accuracy_score as BS  # Balanced accuracy score\nfrom sklearn.preprocessing import OneHotEncoder  # One-hot encoding\nfrom sklearn.utils import shuffle  # Data shuffling\nimport tensorflow_addons as tnfa  # Additional TensorFlow addons\nimport matplotlib.pyplot as mplt  # Plotting library\nimport matplotlib.gridspec as gridspec  # Grid specification for subplots\nfrom distutils.dir_util import copy_tree, remove_tree  # Directory manipulation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDGN  # Image data generator for data augmentation\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-06T17:58:29.205452Z","iopub.execute_input":"2023-06-06T17:58:29.206266Z","iopub.status.idle":"2023-06-06T17:58:40.318090Z","shell.execute_reply.started":"2023-06-06T17:58:29.206220Z","shell.execute_reply":"2023-06-06T17:58:40.316689Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a list of class labels, in this case, \"damage\" and \"no_damage\"\nh_class = [\"damage\", \"no_damage\"]\n\n# Define the base path to a directory containing satellite images of hurricane damage\nh_pth = \"/kaggle/input/satellite-images-of-hurricane-damage/train_another\"\n\n# Create a list of file paths by joining the base path with specific image file names\nh_fpth = [\n    os.path.join(h_pth, \"damage/-93.55964_30.895018.jpeg\"),  # File path for a damaged image\n    os.path.join(h_pth, \"no_damage/-95.061275_29.831535.jpeg\")  # File path for an undamaged image\n]","metadata":{"execution":{"iopub.status.busy":"2023-06-06T17:58:40.320884Z","iopub.execute_input":"2023-06-06T17:58:40.322364Z","iopub.status.idle":"2023-06-06T17:58:40.330023Z","shell.execute_reply.started":"2023-06-06T17:58:40.322305Z","shell.execute_reply":"2023-06-06T17:58:40.328934Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a DenseNet201 model with an input shape of (224, 224, 3) for processing images.\n# include_top=True means that the model includes its fully connected top layer.\nh_modl = DenseNet201(input_shape=(224, 224, 3), include_top=True)\n\n# Define a list of metrics to be used for model evaluation.\nh_metri = [\n    tnf.keras.metrics.CategoricalAccuracy(name='acc'),  # Categorical accuracy metric\n    tnf.keras.metrics.AUC(name='auc'),  # Area Under the ROC Curve metric\n    tnfa.metrics.F1Score(num_classes=2)  # F1 Score metric for a binary classification problem\n]\n\n# Compile the model using the Adam optimizer, categorical cross-entropy loss function,\n# and the specified metrics.\nh_modl.compile(optimizer='adam',\n              loss=tnf.losses.CategoricalCrossentropy(),\n              metrics=h_metri)\n\n# Display a summary of the model architecture, including layers and parameter counts.\nh_modl.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T17:58:40.343263Z","iopub.execute_input":"2023-06-06T17:58:40.344072Z","iopub.status.idle":"2023-06-06T17:58:53.827104Z","shell.execute_reply.started":"2023-06-06T17:58:40.344028Z","shell.execute_reply":"2023-06-06T17:58:53.826204Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the output tensor of the \"avg_pool\" layer from the pre-trained model (h_modl)\nvector = h_modl.get_layer(\"avg_pool\").output\n\n# Create a feature extractor model by specifying the input tensor (h_modl.input)\n# and the output tensor (vector)\nfeature_extractor = tnf.keras.Model(h_modl.input, vector)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T17:58:53.828281Z","iopub.execute_input":"2023-06-06T17:58:53.828851Z","iopub.status.idle":"2023-06-06T17:58:53.992451Z","shell.execute_reply.started":"2023-06-06T17:58:53.828804Z","shell.execute_reply":"2023-06-06T17:58:53.991444Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create empty lists to store feature vectors (P_list) and corresponding labels (Q_list)\nP_list = []\nQ_list = []\n\n# Loop through two classes (0: \"damage\" and 1: \"no_damage\")\nfor f in range(2):    \n    # Construct the path to the class-specific directory\n    h_folder_path = os.path.join(h_pth, h_class[f])\n    \n    # Iterate through files in the class-specific directory\n    for h_phile in os.listdir(h_folder_path):    \n        # Build the full file path\n        h_fpath = os.path.join(h_folder_path, h_phile)\n        \n        # Check if the file has a \".jpeg\" extension; skip it if not\n        if not h_phile.endswith(\".jpeg\"):\n            continue\n        \n        # Load the image with a target size of (224, 224)\n        h_imj = image.load_img(h_fpath, target_size=(224, 224))\n        \n        # Convert the image into a numpy array\n        h_imj_arr = image.img_to_array(h_imj)\n        \n        # Add one more dimension to the image array\n        imj_arr_b = nu.expand_dims(h_imj_arr, axis=0)\n        \n        # Preprocess the image\n        h_input_imj = preprocess_input(imj_arr_b)\n        \n        # Extract features using a pre-trained feature extractor (assuming 'feature_extractor' is defined elsewhere)\n        feature_vec = feature_extractor.predict(h_input_imj)\n    \n        # Append the flattened feature vector to P_list\n        P_list.append(feature_vec.ravel())\n        \n        # Append the class label (0 or 1) to Q_list\n        Q_list.append(f)\n\n# Convert the Python lists to NumPy arrays with data type float32\nP_list = nu.asarray(P_list, dtype=nu.float32)\nQ_list = nu.asarray(Q_list, dtype=nu.float32)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T17:58:53.993752Z","iopub.execute_input":"2023-06-06T17:58:53.994186Z","iopub.status.idle":"2023-06-06T18:22:41.372222Z","shell.execute_reply.started":"2023-06-06T17:58:53.994143Z","shell.execute_reply":"2023-06-06T18:22:41.370983Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert the Python lists P_list and Q_list to NumPy arrays with data type float32\nP = nu.asarray(P_list, dtype=nu.float32)\nQ = nu.asarray(Q_list, dtype=nu.float32)\n\n# Shuffle the data (P and Q) 100 times to randomize the order of samples\nfor s in range(100):\n    P, Q = shuffle(P, Q)\n\n# Print the shapes of the feature matrix P and label matrix Q\nprint(\"The shapes of feature matrix P\")\nprint(P.shape)\nprint(\"\\nThe shapes of label matrix Q\")\nprint(Q.shape)\n\n# Find unique class labels and their corresponding counts in the label matrix Q\nclass_types, conts = nu.unique(Q, return_counts=True)\n\n# Print the unique class labels and their counts\nprint(\"\\nClass labels\")\nprint(class_types)\nprint(\"\\nClass counts\")\nprint(conts)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:22:41.375825Z","iopub.execute_input":"2023-06-06T18:22:41.376955Z","iopub.status.idle":"2023-06-06T18:22:43.870313Z","shell.execute_reply.started":"2023-06-06T18:22:41.376910Z","shell.execute_reply":"2023-06-06T18:22:43.869022Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the feature matrix P and label matrix Q into training and testing sets\n# - The 'test_size' parameter specifies the proportion of the data to be used for testing (in this case, 20%)\n# - 'stratify=Q' ensures that the class distribution in the training and testing sets is similar to that in Q\n# - 'random_state=0' sets a seed for the random number generator to ensure reproducibility\ntrain_P, test_P, train_Q, test_Q = train_test_split(P, \n                                                  Q, \n                                                  test_size=0.2,\n                                                  stratify=Q,\n                                                  random_state=0)\n\n# Print the shapes of the training and testing sets\nprint(\"train_P shape is\")\nprint(train_P.shape)\nprint(\"\\ntest_P shape is\")\nprint(test_P.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:22:43.872129Z","iopub.execute_input":"2023-06-06T18:22:43.873210Z","iopub.status.idle":"2023-06-06T18:22:43.916644Z","shell.execute_reply.started":"2023-06-06T18:22:43.873161Z","shell.execute_reply":"2023-06-06T18:22:43.915362Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nGNB_lin = GaussianNB()\nGNB_lin.fit(train_X, train_Y)\ny_pred = GNB_lin.predict(test_X)\nprint(classification_report(test_Y, y_pred,\n                            target_names=classes))\nprint(confusion_matrix(test_Y, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:22:43.921833Z","iopub.execute_input":"2023-06-06T18:22:43.922178Z","iopub.status.idle":"2023-06-06T18:22:44.119229Z","shell.execute_reply.started":"2023-06-06T18:22:43.922147Z","shell.execute_reply":"2023-06-06T18:22:44.117925Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def the_matrix(value,\n               the_name,\n               title='Confusion Matrix',\n               cmap=None,\n               normalize=True):\n    \"\"\"\n    Plot a confusion matrix.\n\n    Parameters:\n    - value: The confusion matrix values as a numpy array.\n    - the_name: Labels for the classes.\n    - title: The title for the plot (default is 'Confusion Matrix').\n    - cmap: Colormap for the plot (default is None, which uses 'Blues').\n    - normalize: Whether to normalize the confusion matrix (default is True).\n\n    Returns:\n    - None\n    \"\"\"\n\n    # Calculate accuracy and misclassification rate\n    acrcy = nu.trace(value) / float(nu.sum(value))\n    mis = 1 - acrcy\n\n    # Set the colormap to 'Blues' if not specified\n    if cmap is None:\n        cmap = mplt.get_cmap('Blues')\n\n    # Create a figure for the plot with specified size\n    mplt.figure(figsize=(8, 6))\n\n    # Plot the confusion matrix as an image\n    mplt.imshow(value, interpolation='nearest', cmap=cmap)\n\n    # Set the title of the plot\n    mplt.title(title)\n\n    # Add a color bar to the plot\n    mplt.colorbar()\n\n    # Customize x and y axis labels if class labels are provided\n    if the_name is not None:\n        the_marking = nu.arange(len(the_name))\n        mplt.xticks(the_marking, the_name, rotation=90)\n        mplt.yticks(the_marking, the_name)\n\n    # Normalize the confusion matrix if specified\n    if normalize:\n        value = value.astype('float') / value.sum(axis=1)[:, nu.newaxis]\n\n    # Set the threshold for text color based on normalization\n    h_boundary = value.max() / 1.5 if normalize else value.max() / 2\n\n    # Add text annotations to the plot\n    for s, t in itertools.product(range(value.shape[0]), range(value.shape[1])):\n        if normalize:\n            mplt.text(t, s, \"{:0.4f}\".format(value[s, t]),\n                      horizontalalignment=\"center\",\n                      color=\"white\" if value[s, t] > h_boundary else \"black\")\n        else:\n            mplt.text(t, s, \"{:,}\".format(value[s, t]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if value[s, t] > h_boundary else \"black\")\n\n    # Adjust the layout of the plot for better appearance\n    mplt.tight_layout()\n\n    # Set labels for y-axis and x-axis\n    mplt.ylabel('ACTUAL', fontsize=20)\n    mplt.xlabel('PREDICTED', fontsize=14)\n\n    # Show the plot\n    mplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a dictionary 'font' to set the font properties\nfont = {'family': 'serif',  # Font family (serif)\n        'weight': 'bold',   # Font weight (bold)\n        'size': 20}         # Font size (20 points)\n\n# Use 'mplt.rc' to set the global font properties using the 'font' dictionary\nmplt.rc('font', **font)\n\n# Set the font family to \"serif\" for all plots\nmplt.rcParams[\"font.family\"] = \"serif\"\n\n# Set the default font size for all plots to 14 points\nmplt.rcParams[\"font.size\"] = 14","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Call the 'the_matrix' function to plot a confusion matrix with the provided arguments\nthe_matrix(value=nu.array([[966, 34], [26, 974]]),  # Confusion matrix values\n           normalize=False,                         # Not normalizing the values\n           the_name=[\"Damage\", \"NonDamage\"],        # Class labels\n           title=\"GNB\")                         # Title for the plot","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import the OneHotEncoder class from the appropriate library (not shown in the provided code)\nn_encoder = OneHotEncoder(sparse=False)\n\n# Fit the encoder to the training labels (train_Y), reshaping them to a single column\nn_encoder.fit(train_Q.reshape(-1, 1))\n\n# Transform the training labels (train_Q) into one-hot encoded format\ne_train_Q = n_encoder.transform(train_Q.reshape(-1, 1))\n\n# Transform the testing labels (test_Q) into one-hot encoded format\ne_test_Q = n_encoder.transform(test_Q.reshape(-1, 1))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a function to create a neural network model\ndef create_model():\n    h_modl = Sequential()\n    # Add a dense layer with 1000 units, input dimension of 1920, and ReLU activation\n    h_modl.add(Dense(1000, input_dim=1920, activation=\"relu\"))\n    # Add dropout regularization with a rate of 0.3\n    h_modl.add(Dropout(0.3))\n    # Add another dense layer with 2 units, L2 regularization of 0.1, and linear activation\n    h_modl.add(Dense(2, kernel_regularizer=l2(0.1), activation=\"linear\"))\n    # Compile the model with Adam optimizer, categorical hinge loss, and specified metrics\n    h_modl.compile(optimizer=tnf.keras.optimizers.Adam(lr=0.0001),\n                   loss=\"categorical_hinge\", metrics=h_metri)\n    return h_modl\n\n# Define the number of training epochs\nepoch = 1000\n\n# Create the model using the 'create_model' function\nh_modl = create_model()\n\n# Train the model on the training data with validation split, specified epochs, batch size, and verbosity\nhistory = h_modl.fit(train_P, e_train_Q,\n                     validation_split=0.15,\n                     epochs=epoch, batch_size=64, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:22:44.136580Z","iopub.execute_input":"2023-06-06T18:22:44.137589Z","iopub.status.idle":"2023-06-06T18:35:07.707219Z","shell.execute_reply.started":"2023-06-06T18:22:44.137543Z","shell.execute_reply":"2023-06-06T18:35:07.705954Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a figure with 3 subplots in a 1x3 grid with a specified figsize\nfig, aex = mplt.subplots(1, 3, figsize=(20, 10))\naex = aex.ravel()\n\n# Iterate over the metrics [\"acc\", \"auc\", \"loss\"]\nfor s, the_metri in enumerate([\"acc\", \"auc\", \"loss\"]):\n    # Plot the training and validation metrics for each metric\n    aex[s].plot(history.history[the_metri])\n    aex[s].plot(history.history[\"val_\" + the_metri])\n    \n    # Set the title, x-axis label, and y-axis label for each subplot\n    aex[s].set_title(\"Model {}\".format(the_metri))\n    aex[s].set_xlabel(\"Epochs\")\n    aex[s].set_ylabel(the_metri)\n    \n    # Add legends to differentiate between training and validation data\n    aex[s].legend([\"train\", \"val\"])\n    \n# Define font properties for the plots\nfont = {'family': 'serif',  # Font family (serif)\n        'weight': 'bold',    # Font weight (bold)\n        'size': 12}          # Font size (12 points)\n\n# Set the specified font properties for the entire plot\nmplt.rc('font', **font)\n\n# Set the font family to \"serif\" for all plots\nmplt.rcParams[\"font.family\"] = \"serif\"","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:35:07.709619Z","iopub.execute_input":"2023-06-06T18:35:07.710610Z","iopub.status.idle":"2023-06-06T18:35:08.528692Z","shell.execute_reply.started":"2023-06-06T18:35:07.710565Z","shell.execute_reply":"2023-06-06T18:35:08.527378Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create an array 'e' of evenly spaced values from 1 to 'epoch' with 'epoch' data points\ne = nu.linspace(1, epoch, epoch)\n\n# Create a figure with one subplot using Seaborn (imported as 'sb')\nfig, aexes = mplt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n\n# Plot the training loss over epochs\nsb.lineplot(x=e, y=history.history[\"loss\"], aex=aexes, label=\"train\")\n\n# Plot the validation loss over epochs\nsb.lineplot(x=e, y=history.history[\"val_loss\"], aex=aexes, label=\"val\")\n\n# Set the y-axis label for the plot\naexes.set_ylabel(\"Categorical Hinge Loss\")\n\n# Set the x-axis label for the plot\naexes.set_xlabel(\"Epoch\")","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:35:08.530080Z","iopub.execute_input":"2023-06-06T18:35:08.530491Z","iopub.status.idle":"2023-06-06T18:35:08.917934Z","shell.execute_reply.started":"2023-06-06T18:35:08.530451Z","shell.execute_reply":"2023-06-06T18:35:08.916705Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict class labels for test_P using the trained model and get the class with the highest probability\nq_pred = nu.argmax(h_modl.predict(test_P), axis=-1)\n\n# Print a classification report to evaluate the model's performance\n# The 'target_names' parameter is used to label the classes in the report\nprint(classification_report(test_Q, q_pred, targeted_names=h_class))\n\n# Print a confusion matrix to visualize the model's performance\nprint(confusion_matrix(test_Q, q_pred))","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:35:08.919843Z","iopub.execute_input":"2023-06-06T18:35:08.921305Z","iopub.status.idle":"2023-06-06T18:35:09.783899Z","shell.execute_reply.started":"2023-06-06T18:35:08.921248Z","shell.execute_reply":"2023-06-06T18:35:09.782494Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a figure with 2 subplots in a 2x1 grid\nfig, aex = mplt.subplots(2, 1)\n\n# Plot the training loss in the first subplot ('aex[0]') with a blue line and label\naex[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n\n# Plot the testing loss in the first subplot ('aex[0]') with a red line and label\naex[0].plot(history.history['val_loss'], color='r', label=\"Testing loss\")\n\n# Add a legend to the first subplot to differentiate between training and testing loss\nlegend = aex[0].legend(loc='best', shadow=True)\n\n# Display the plot\nmplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:35:09.786002Z","iopub.execute_input":"2023-06-06T18:35:09.786878Z","iopub.status.idle":"2023-06-06T18:35:10.124998Z","shell.execute_reply.started":"2023-06-06T18:35:09.786810Z","shell.execute_reply":"2023-06-06T18:35:10.123710Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def the_matrix(value,\n               the_name,\n               title='Confusion matrix',\n               cmap=None,\n               normalize=True):\n\n    # Calculate accuracy and misclassification rate\n    acrcy = nu.trace(value) / float(nu.sum(value))\n    mis = 1 - acrcy\n\n    # Set the colormap to 'Blues' if not specified\n    if cmap is None:\n        cmap = mplt.get_cmap('Blues')\n\n    # Create a figure for the plot with specified size\n    mplt.figure(figsize=(8, 6))\n\n    # Plot the confusion matrix as an image\n    mplt.imshow(value, interpolation='nearest', cmap=cmap)\n\n    # Set the title of the plot\n    mplt.title(title)\n\n    # Add a color bar to the plot\n    mplt.colorbar()\n\n    # Customize x and y axis labels if class labels are provided\n    if the_name is not None:\n        the_marking = nu.arange(len(the_name))\n        mplt.xticks(the_marking, the_name, rotation=90)\n        mplt.yticks(the_marking, the_name)\n\n    # Normalize the confusion matrix if specified\n    if normalize:\n        value = value.astype('float') / value.sum(axis=1)[:, nu.newaxis]\n\n    # Set the threshold for text color based on normalization\n    h_boundary = value.max() / 1.5 if normalize else value.max() / 2\n\n    # Add text annotations to the plot\n    for s, t in itertools.product(range(value.shape[0]), range(value.shape[1])):\n        if normalize:\n            mplt.text(t, s, \"{:0.4f}\".format(value[s, t]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if value[s, t] > h_boundary else \"black\")\n        else:\n            mplt.text(t, s, \"{:,}\".format(value[s, t]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if value[s, t] > h_boundary else \"black\")\n\n    # Adjust the layout of the plot for better appearance\n    mplt.tight_layout()\n\n    # Set labels for y-axis and x-axis\n    mplt.ylabel('ACTUAL', fontsize=20)\n    mfont = {'family': 'serif', 'weight': 'bold'}\n    mplt.xlabel('PREDICTED', fontsize=14)\n    font = {'family': 'serif', 'weight': 'bold'}\n\n    # Display the plot\n    mplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:35:10.127146Z","iopub.execute_input":"2023-06-06T18:35:10.128025Z","iopub.status.idle":"2023-06-06T18:35:10.148749Z","shell.execute_reply.started":"2023-06-06T18:35:10.127974Z","shell.execute_reply":"2023-06-06T18:35:10.147403Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a dictionary 'font' to set the font properties\nfont = {'family': 'serif',  # Font family (serif)\n        'weight': 'bold',    # Font weight (bold)\n        'size': 20}          # Font size (20 points)\n\n# Use 'mplt.rc' to set the global font properties using the 'font' dictionary\nmplt.rc('font', **font)\n\n# Set the font family to \"serif\" for all plots\nmplt.rcParams[\"font.family\"] = \"serif\"\n\n# Set the default font size for all plots to 14 points\nmplt.rcParams[\"font.size\"] = 14","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:35:10.150573Z","iopub.execute_input":"2023-06-06T18:35:10.151542Z","iopub.status.idle":"2023-06-06T18:35:10.167414Z","shell.execute_reply.started":"2023-06-06T18:35:10.151494Z","shell.execute_reply":"2023-06-06T18:35:10.165969Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Call the 'the_matrix' function to plot a confusion matrix with the provided arguments\nthe_matrix(value=nu.array([[960, 40], [13, 987]]),  # Confusion matrix values\n           normalize=False,                         # Not normalizing the values\n           the_name=[\"Damage\", \"NonDamage\"],       # Class labels\n           title=\"DenseNet201_GNB\")            # Title for the plot ","metadata":{"execution":{"iopub.status.busy":"2023-06-06T18:36:02.166051Z","iopub.execute_input":"2023-06-06T18:36:02.166519Z","iopub.status.idle":"2023-06-06T18:36:02.485801Z","shell.execute_reply.started":"2023-06-06T18:36:02.166480Z","shell.execute_reply":"2023-06-06T18:36:02.484562Z"},"trusted":true},"outputs":[],"execution_count":null}]}